<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title><%=L('index1', language, 'News') %></title>
    <link rel="shortcut icon" href="../public/images/Favicon.png" type="image/x-icon">
    <%- include('./components/head.ejs.html') %>
    <style>
        .content-body {
            margin: 10px 0;
            max-height: 600px;
            overflow-y: auto;
            padding: 10px;
        }

        ::-webkit-scrollbar {
            width: 4px; /* Width of the entire scrollbar */
        }

        ::-webkit-scrollbar-thumb {
            background-color: #888; 
            border-radius: 5px; 
        }
        .news-content{
            max-height: 270px;
            overflow-y: auto;
        }
    </style>
</head>

<body>
    <header>
     
        <div class="logo d-flex align-items-center">
                <span class="material-symbols-outlined btn btn-light px-2 py-0 me-3 burger-menu" style="display: none;" onclick="toggleMenu()">
                    menu
                </span>
             
            <a href="/"><img src="/public/images/CoachMate.png" alt=""></a>
        </div>
        <%- include('./components/profile_bar.ejs.html') %>
    </header>
    <main>
        <%- include('./components/nav_bar.ejs.html') %>
            <div class="content">
                <div class="content-head p-3 element-box">
                    <h4>AI Realtime API with Voice Detection</h4>
                    <button id="start-detection" class="btn btn-light"><img src="https://www.pngarts.com/files/2/Play-PNG-Download-Image.png" width="20" alt=""></button>

                </div>
                <div class="content-body element-box">
                    <div id="messageContainer" class="mt-1"></div>
                </div>
            </div>
    </main>
    <footer></footer>

    <script type="text/javascript" src="https://s2.webapi.ai/chat-widget/uniq-chat.js"></script>

    <script>
        var ailabs_user_info = {
            'client': 'c1463',
            'welcome_message': 'Welcome to the chat ðŸ‘‹',
            'popup_mode': 0, //0-off, 1-auto popup after 10 seconds for new users
            'input_comment': 'Type your message or /start to restart'
        };
        AILabsChatStart();
    </script>


    <!-- END OF MODALS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        var globalNews;
        var globalNewsId;
        var recordState = true;

        $(document).ready(function () {
            loading(1);
          
            loading(0);
        });

        $(document).ready(function () {
            var currentUrl = window.location.pathname;

            $(".nav-bar ul li").each(function () {
                var listItem = $(this);
                var listItemLink = listItem.find("a");
                var listItemHref = listItemLink.attr("href");

                if (currentUrl === listItemHref) {
                    listItem.addClass("active");
                } else {
                    listItem.removeClass("active");
                }
            });
        });


       

    </script>

<script>
    const startDetectionButton = document.getElementById('start-detection');

    let mediaRecorder, audioContext, analyser, dataArray, silenceTimeout, audioChunks = [];
    let recording = false;
    const messageContainer = document.getElementById('messageContainer');
    const utterance = new SpeechSynthesisUtterance();

    const socket = new WebSocket('ws://localhost:4001');

    socket.onopen = () => {
      console.log('Connected to server');
    };

    socket.onclose = () => {
      console.log('Disconnected from server');
    };

    socket.onmessage = (event) => {
      console.log(event)
      const message = document.createElement('p');
      message.textContent = `AI: ${event.data}`;

      messageContainer.appendChild(message);
      utterance.text = event.data;

    };


    startDetectionButton.addEventListener('click', async () => {
      // Get the microphone input
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // Create an AudioContext for VAD
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      dataArray = new Uint8Array(analyser.fftSize);

      // Create a MediaStreamDestination to record audio
      const destination = audioContext.createMediaStreamDestination();
      source.connect(analyser);
      source.connect(destination); // Connect source to the destination

      checkForVoice(stream); // Pass the destination stream to check for voice

      startDetectionButton.disabled = true;

    });



    function checkForVoice(stream) {
      analyser.getByteTimeDomainData(dataArray);

      // Calculate average audio level
      const rms = Math.sqrt(dataArray.reduce((sum, value) => sum + (value - 128) ** 2, 0) / dataArray.length);
      const silenceThreshold = 10; // Adjust based on your requirements

      if (rms > silenceThreshold) {
        console.log('Voice detected');
        if (!recording) {
          socket.send('started');
          startRecording(stream); // Start recording with the provided stream
        }
        clearTimeout(silenceTimeout);
        silenceTimeout = null;
      } else {
        if (recording && !silenceTimeout) {
          silenceTimeout = setTimeout(() => {
            stopRecording();
          }, 3000); // Stop recording after 3 seconds of silence
        }
      }

      requestAnimationFrame(() => checkForVoice(stream)); // Keep checking for voice activity
    }

    function startRecording(stream) {
      console.log('Starting recording...');
      audioChunks = []; // Reset the buffer

      mediaRecorder = new MediaRecorder(stream);

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && socket.readyState == 1) {
          socket.send(event.data);
        }
      };

      mediaRecorder.start(100); // Capture every 100ms
      console.log('Streaming started...'); // Start recording
      recording = true; // Mark as recording
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
        console.log('Stopped recording, sending audio buffer to server...');
        socket.send('finished');
      }
      recording = false; // Mark as not recording
    }

    function sendAudioBuffer() {
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' }); // Combine audio chunks into a Blob
      const reader = new FileReader();
      reader.readAsArrayBuffer(audioBlob);
      reader.onloadend = () => {
        // const arrayBuffer = reader.result;
        // socket.send(arrayBuffer); // Send the audio buffer to the server

      };
    }

    function stopDetection() {
      stopRecording(); // Stop any ongoing recording
      audioContext.close(); // Close the audio context
      startDetectionButton.disabled = false;

    }
  </script>
</body>

</html>